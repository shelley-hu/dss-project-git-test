{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "creator": "admin",
    "createdOn": 1649358378556,
    "tags": [],
    "customFields": {},
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.6.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "admin"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 26,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%pylab inline"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "Populating the interactive namespace from numpy and matplotlib\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 2,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nfrom dataiku import pandasutils as pdu\nimport pandas as pd"
      ],
      "outputs": []
    },
    {
      "execution_count": 3,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pprint\nclient \u003d dataiku.api_client()\nproject \u003d client.list_projects()\nproject \u003d client.get_default_project()\n\nprint(\"My project is %s\" % project.project_key)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "My project is ADMIN_PROJECT\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 5,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#Modify the catalog, schema and table of this dataset\ndatasets \u003d project.list_datasets()\nfor dataset in datasets:\n    if (dataset.type \u003d\u003d \u0027Snowflake\u0027):\n        if (dataset.name \u003d\u003d \u0027BASKETBALLv2_BASKETBALL_EXPERIENCE_SF\u0027):\n            print(\"\\n\\nOnly modify the input SF dataset name: BASKETBALLv2_BASKETBALL_EXPERIENCE_SF\")\n            print(\"Name: %s\" % dataset.name)\n            print(\"Type: %s\" % dataset.type)\n            dataset1 \u003d dataset.to_dataset()\n            print(\"Attributes of dataset %s\" %dir(dataset1))\n            settings \u003d dataset1.get_settings()\n            settings_raw \u003d settings.get_raw()\n            params \u003d settings.get_raw_params()\n            print(\"\\n\\nParams is (BEFORE):\")\n            pprint.pprint(params)\n            quit()\n                  \n            #modify catalog, schma, table of dataset\n            settings_raw[\u0027params\u0027][\u0027catalog\u0027] \u003d \"INTEGRATION_TESTS\"\n            settings_raw[\u0027params\u0027][\u0027schema\u0027] \u003d \"SCHEMA_TEST\"\n            settings_raw[\u0027params\u0027][\u0027table\u0027] \u003d\"SHU_SF_NEW_OUTPUT\"\n            settings.save()\n            settings_raw[\"schema\"] \u003d {\"columns\":[]}\n            settings.save()\n            settings \u003d dataset1.autodetect_settings()\n            settings.save()\n                        \n                \n            params \u003d settings.get_raw_params()\n            print(\"\\n\\nParams is (AFTER):\")\n            pprint.pprint(params)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "\n\nOnly modify the input SF dataset name: BASKETBALLv2_BASKETBALL_EXPERIENCE_SF\nName: BASKETBALLv2_BASKETBALL_EXPERIENCE_SF\nType: Snowflake\nAttributes of dataset [\u0027_FS_TYPES\u0027, \u0027_SQL_TYPES\u0027, \u0027__class__\u0027, \u0027__delattr__\u0027, \u0027__dict__\u0027, \u0027__dir__\u0027, \u0027__doc__\u0027, \u0027__eq__\u0027, \u0027__format__\u0027, \u0027__ge__\u0027, \u0027__getattribute__\u0027, \u0027__gt__\u0027, \u0027__hash__\u0027, \u0027__init__\u0027, \u0027__init_subclass__\u0027, \u0027__le__\u0027, \u0027__lt__\u0027, \u0027__module__\u0027, \u0027__ne__\u0027, \u0027__new__\u0027, \u0027__reduce__\u0027, \u0027__reduce_ex__\u0027, \u0027__repr__\u0027, \u0027__setattr__\u0027, \u0027__sizeof__\u0027, \u0027__str__\u0027, \u0027__subclasshook__\u0027, \u0027__weakref__\u0027, \u0027autodetect_settings\u0027, \u0027build\u0027, \u0027clear\u0027, \u0027client\u0027, \u0027compute_metrics\u0027, \u0027copy_to\u0027, \u0027create_analysis\u0027, \u0027create_clustering_ml_task\u0027, \u0027create_prediction_ml_task\u0027, \u0027create_statistics_worksheet\u0027, \u0027dataset_name\u0027, \u0027delete\u0027, \u0027delete_analyses\u0027, \u0027exists\u0027, \u0027get_as_core_dataset\u0027, \u0027get_definition\u0027, \u0027get_last_metric_values\u0027, \u0027get_metadata\u0027, \u0027get_metric_history\u0027, \u0027get_object_discussions\u0027, \u0027get_schema\u0027, \u0027get_settings\u0027, \u0027get_statistics_worksheet\u0027, \u0027get_usages\u0027, \u0027get_zone\u0027, \u0027id\u0027, \u0027iter_rows\u0027, \u0027list_analyses\u0027, \u0027list_partitions\u0027, \u0027list_statistics_worksheets\u0027, \u0027move_to_zone\u0027, \u0027name\u0027, \u0027new_code_recipe\u0027, \u0027new_recipe\u0027, \u0027project\u0027, \u0027project_key\u0027, \u0027run_checks\u0027, \u0027set_definition\u0027, \u0027set_metadata\u0027, \u0027set_schema\u0027, \u0027share_to_zone\u0027, \u0027synchronize_hive_metastore\u0027, \u0027test_and_detect\u0027, \u0027unshare_from_zone\u0027, \u0027update_from_hive\u0027, \u0027uploaded_add_file\u0027, \u0027uploaded_list_files\u0027]\n\n\nParams is (BEFORE):\n{\u0027catalog\u0027: \u0027INTEGRATION_TESTS\u0027,\n \u0027connection\u0027: \u0027test_snowflake\u0027,\n \u0027mode\u0027: \u0027table\u0027,\n \u0027normalizeDoubles\u0027: True,\n \u0027notReadyIfEmpty\u0027: False,\n \u0027partitioningType\u0027: \u0027custom\u0027,\n \u0027readColsWithUnknownTzAsDates\u0027: False,\n \u0027readSQLDateColsAsDSSDates\u0027: True,\n \u0027schema\u0027: \u0027SCHEMA_TEST\u0027,\n \u0027table\u0027: \u0027SHU_SF_NEW_OUTPUT\u0027,\n \u0027tableCreationMode\u0027: \u0027auto\u0027,\n \u0027writeInsertBatchSize\u0027: 10000,\n \u0027writeJDBCBadDataBehavior\u0027: \u0027DISCARD_ROW\u0027}\n\n\nParams is (AFTER):\n{\u0027catalog\u0027: \u0027INTEGRATION_TESTS\u0027,\n \u0027connection\u0027: \u0027test_snowflake\u0027,\n \u0027mode\u0027: \u0027table\u0027,\n \u0027normalizeDoubles\u0027: True,\n \u0027notReadyIfEmpty\u0027: False,\n \u0027partitioningType\u0027: \u0027custom\u0027,\n \u0027readColsWithUnknownTzAsDates\u0027: False,\n \u0027readSQLDateColsAsDSSDates\u0027: True,\n \u0027schema\u0027: \u0027SCHEMA_TEST\u0027,\n \u0027table\u0027: \u0027SHU_SF_NEW_OUTPUT\u0027,\n \u0027tableCreationMode\u0027: \u0027auto\u0027,\n \u0027writeInsertBatchSize\u0027: 10000,\n \u0027writeJDBCBadDataBehavior\u0027: \u0027DISCARD_ROW\u0027}\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "\n"
      ],
      "outputs": []
    }
  ]
}