{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "creator": "admin",
    "createdOn": 1649358378556,
    "tags": [],
    "customFields": {},
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.6.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "admin"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%pylab inline"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nfrom dataiku import pandasutils as pdu\nimport pandas as pd"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pprint\nclient \u003d dataiku.api_client()\nproject \u003d client.list_projects()\nproject \u003d client.get_default_project()\n\nprint(\"My project is %s\" % project.project_key)"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "datasets \u003d project.list_datasets()\nfor dataset in datasets:\n    if (dataset.type \u003d\u003d \u0027Snowflake\u0027):\n        print(\"\\n\\n Only modify the input SF dataset name: \" %index)\n        print(\"Name: %s\" % dataset.name)\n        print(\"Type: %s\" % dataset.type)\n#       print(\"Connection: %s\" % dataset.connection)\n#       dataset1 \u003d project.get_dataset(dataset.name), we can use to_dataset() to conver it too\n        dataset1 \u003d dataset.to_dataset()\n#        print(\"Obj type of dataset is: %s\" % type(dataset))\n#        print(\"Attributes of dataset is: %s\" %dir(dataset))\n#        print(\"Obj type of dataset1 is: %s\" % type(dataset1))\n#        print(\"Attributes of dataset1 is: %s\" %dir(dataset1))\n\n\n        settings \u003d dataset1.get_settings()\n#        print(\"Attributes of settings is: \\n%s\" %dir(settings))\n        settings_raw \u003d settings.get_raw()\n        params \u003d settings.get_raw_params()\n        print(\"\\n\\nParams is:\\n\")\n        pprint.pprint(params)\n#        print(\"\\n\\nSettings raw is:\\n\")\n#        pprint.pprint(settings_raw)\n        index +\u003d 1\n        \n        #modify schma of dataset\n        #https://doc.dataiku.com/dss/latest/python-api/datasets-other.html#basic-operations\n#        for column in settings_raw[\u0027schema\u0027][\u0027columns\u0027]:\n        # Now, let\u0027s add a new column in the schema\n        #settings.add_raw_schema_column({\"name\" : \"shelley_test\", \"type\": \"string\"})     \n        # If we changed the settings, we must save\n        #settings.save()\n        \n        for column in settings.schema_columns :\n            if column[\"name\"] \u003d\u003d \u0027shelley_test\u0027:\n                print(\"Have column name\u003d%s type\u003d%s\" % (column[\"name\"], column[\"type\"]))        \n#        break"
      ],
      "outputs": []
    }
  ]
}