{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "creator": "admin",
    "createdOn": 1649354817182,
    "tags": [],
    "customFields": {},
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.6.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "admin"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 17,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%pylab inline"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "Populating the interactive namespace from numpy and matplotlib\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 18,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nfrom dataiku import pandasutils as pdu\nimport pandas as pd\nimport pprint"
      ],
      "outputs": []
    },
    {
      "execution_count": 19,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "client \u003d dataiku.api_client()\nproject \u003d client.list_projects()\nproject \u003d client.get_default_project()\n\nprint(\"My project is %s\" % project.project_key)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "My project is ADMIN_PROJECT\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 21,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#API reference for autodetect_settings: \n#https://doc.dataiku.com/dss/latest/python-api/datasets-reference.html\n#Detects appropriate settings for this dataset using Dataiku detection engine\ndatasets \u003d project.list_datasets()\nindex \u003d 1\nfor dataset in datasets:\n#    if (dataset.type \u003d\u003d \u0027PostgreSQL\u0027):\n    if (dataset.type \u003d\u003d \u0027Snowflakeeeee\u0027):\n        print(\"\\n\\n \u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003cDataset %d\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\" %index)\n        print(\"Name: %s\" % dataset.name)\n        print(\"Type: %s\" % dataset.type)\n#       print(\"Connection: %s\" % dataset.connection)\n#       dataset1 \u003d project.get_dataset(dataset.name), we can use to_dataset() to conver it too\n        dataset1 \u003d dataset.to_dataset()\n#        print(\"Obj type of dataset is: %s\" % type(dataset))\n#        print(\"Attributes of dataset is: %s\" %dir(dataset))\n#        print(\"Obj type of dataset1 is: %s\" % type(dataset1))\n#        print(\"Attributes of dataset1 is: %s\" %dir(dataset1))\n\n\n        settings \u003d dataset1.get_settings()\n#        print(\"Attributes of settings is: \\n%s\" %dir(settings))\n        settings_raw \u003d settings.get_raw()\n        params \u003d settings.get_raw_params()\n        print(\"\\n\\nParams is:\\n\")\n        pprint.pprint(params)\n#        print(\"\\n\\nSettings raw is:\\n\")\n#        pprint.pprint(settings_raw)\n        index +\u003d 1\n        \n        #modify schma of dataset\n        #https://doc.dataiku.com/dss/latest/python-api/datasets-other.html#basic-operations\n#        for column in settings_raw[\u0027schema\u0027][\u0027columns\u0027]:\n        # Now, let\u0027s add a new column in the schema\n        #settings.add_raw_schema_column({\"name\" : \"shelley_test\", \"type\": \"string\"})     \n        # If we changed the settings, we must save\n        #settings.save()\n        \n        for column in settings.schema_columns :\n            if column[\"name\"] \u003d\u003d \u0027shelley_test\u0027:\n                print(\"Have column name\u003d%s type\u003d%s\" % (column[\"name\"], column[\"type\"]))        \n#        break"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "\n\n \u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003cDataset 1\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\nName: BASKETBALL_SF_SQL\nType: Snowflake\n\n\nParams is:\n\n{\u0027connection\u0027: \u0027test_snowflake\u0027,\n \u0027mode\u0027: \u0027table\u0027,\n \u0027normalizeDoubles\u0027: True,\n \u0027notReadyIfEmpty\u0027: False,\n \u0027partitioningType\u0027: \u0027custom\u0027,\n \u0027readColsWithUnknownTzAsDates\u0027: False,\n \u0027readSQLDateColsAsDSSDates\u0027: True,\n \u0027schema\u0027: \u0027INTEGRATION_TESTS\u0027,\n \u0027table\u0027: \u0027${projectKey}_BASKETBALL_SF_SQL\u0027,\n \u0027tableCreationMode\u0027: \u0027auto\u0027,\n \u0027writeInsertBatchSize\u0027: 10000,\n \u0027writeJDBCBadDataBehavior\u0027: \u0027DISCARD_ROW\u0027}\n\n\n \u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003cDataset 2\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\nName: BASKETBALLv2_BASKETBALL_EXPERIENCE_SF\nType: Snowflake\n\n\nParams is:\n\n{\u0027catalog\u0027: \u0027INTEGRATION_TESTS\u0027,\n \u0027connection\u0027: \u0027test_snowflake\u0027,\n \u0027mode\u0027: \u0027table\u0027,\n \u0027normalizeDoubles\u0027: True,\n \u0027notReadyIfEmpty\u0027: False,\n \u0027partitioningType\u0027: \u0027custom\u0027,\n \u0027readColsWithUnknownTzAsDates\u0027: False,\n \u0027readSQLDateColsAsDSSDates\u0027: True,\n \u0027schema\u0027: \u0027\u0027,\n \u0027table\u0027: \u0027BASKETBALLv2_BASKETBALL_EXPERIENCE_SF\u0027,\n \u0027tableCreationMode\u0027: \u0027auto\u0027,\n \u0027writeInsertBatchSize\u0027: 10000,\n \u0027writeJDBCBadDataBehavior\u0027: \u0027DISCARD_ROW\u0027}\n\n\n \u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003cDataset 3\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\nName: Basketball_experience_sql2\nType: PostgreSQL\n\n\nParams is:\n\n{\u0027connection\u0027: \u0027postgres_conn\u0027,\n \u0027mode\u0027: \u0027table\u0027,\n \u0027normalizeDoubles\u0027: True,\n \u0027notReadyIfEmpty\u0027: False,\n \u0027partitioningType\u0027: \u0027custom\u0027,\n \u0027readColsWithUnknownTzAsDates\u0027: False,\n \u0027readSQLDateColsAsDSSDates\u0027: True,\n \u0027table\u0027: \u0027${projectKey}_basketball_experience_sql2\u0027,\n \u0027tableCreationMode\u0027: \u0027auto\u0027,\n \u0027writeInsertBatchSize\u0027: 10000,\n \u0027writeJDBCBadDataBehavior\u0027: \u0027DISCARD_ROW\u0027,\n \u0027writeWithCopyBadDataBehavior\u0027: \u0027NOVERIFY_ERROR\u0027}\n\n\n \u003c\u003c\u003c\u003c\u003c\u003c\u003c\u003cDataset 4\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\u003e\nName: SF_new_output\nType: Snowflake\n\n\nParams is:\n\n{\u0027catalog\u0027: \u0027INTEGRATION_TESTS\u0027,\n \u0027connection\u0027: \u0027test_snowflake\u0027,\n \u0027mode\u0027: \u0027table\u0027,\n \u0027normalizeDoubles\u0027: True,\n \u0027notReadyIfEmpty\u0027: False,\n \u0027partitioningType\u0027: \u0027custom\u0027,\n \u0027readColsWithUnknownTzAsDates\u0027: False,\n \u0027readSQLDateColsAsDSSDates\u0027: True,\n \u0027schema\u0027: \u0027SCHEMA_TEST\u0027,\n \u0027table\u0027: \u0027${projectKey}_SF_NEW_OUTPUT\u0027,\n \u0027tableCreationMode\u0027: \u0027auto\u0027,\n \u0027writeInsertBatchSize\u0027: 10000,\n \u0027writeJDBCBadDataBehavior\u0027: \u0027DISCARD_ROW\u0027}\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    }
  ]
}