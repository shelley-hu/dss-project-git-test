{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "creator": "admin",
    "createdOn": 1649191930287,
    "tags": [],
    "customFields": {},
    "hide_input": false,
    "language_info": {
      "name": "python",
      "version": "3.6.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "modifiedBy": "admin"
  },
  "nbformat": 4,
  "nbformat_minor": 1,
  "cells": [
    {
      "execution_count": 9,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%pylab inline"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "Populating the interactive namespace from numpy and matplotlib\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 3,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import dataiku\nfrom dataiku import pandasutils as pdu\nimport pandas as pd"
      ],
      "outputs": []
    },
    {
      "execution_count": 8,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "client \u003d dataiku.api_client()\n#prj\u003d client.get_project(dataiku.default_project_key())\n#datasets \u003d prj.list_datasets()\n\n#client \u003d DSSClient(host, apiKey)\ndss_projects \u003d client.list_project_keys()\nprint(dss_projects)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "[\u0027ADMIN_PROJECT\u0027, \u0027BACKEND_BREAKER\u0027, \u0027BASKETBALLv2\u0027, \u0027BASKETBALLv2_2\u0027, \u0027CUSTOMER_CHURN_BROKEN\u0027, \u0027DKU_TSHIRTS\u0027, \u0027DKU_TUTORIAL_BASICS_101\u0027, \u0027GROUP_A_PROJECT\u0027, \u0027GROUP_B_PROJECT\u0027, \u0027THEBIGSLEEP\u0027]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 22,
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for ProjectKey in dss_projects:\n    project \u003d client.get_project(ProjectKey)\n    datasets \u003d project.list_datasets()\n    print(\"Datasets in Project: \", ProjectKey)\n    for dataset in datasets:\n        print (dataset.type)\n        if (dataset.type \u003d PostgreSQL):\n#     project_metadata \u003d project.get_metadata()\n#     print(\"The output is\", ProjectKey, project_metadata.shortDesc)\n\n \n#     print(project_metadata)\n#     project_metadata[\u0027tags\u0027] \u003d [\u0027tag1\u0027,\u0027tag2\u0027]\n#     project.set_metadata(project_metadata)\n\n#     project_permissions \u003d project.get_permissions()\n#     project_permissions[\u0027permissions\u0027].append({\u0027group\u0027:\u0027data_scientists\u0027,\u0027readProjectContent\u0027: True, \u0027readDashboards\u0027: True})\n#     project.set_permissions(project_permissions)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "text": "Datasets in Project:  ADMIN_PROJECT\nDatasets in Project:  BACKEND_BREAKER\nUploadedFiles\nDatasets in Project:  BASKETBALLv2\nFilesystem\nFilesystem\nFilesystem\nUploadedFiles\nPostgreSQL\nFilesystem\nFilesystem\nFilesystem\nFilesystem\nFilesystem\nFilesystem\nFilesystem\nPostgreSQL\nFilesystem\nFilesystem\nFilesystem\nFilesystem\nFilesystem\nFilesystem\nFilesystem\nFilesystem\nPostgreSQL\nFilesystem\nFilesystem\nFilesystem\nFilesystem\nFilesystem\nDatasets in Project:  BASKETBALLv2_2\nFilesystem\nFilesystem\nFilesystem\nUploadedFiles\nPostgreSQL\nFilesystem\nFilesystem\nFilesystem\nFilesystem\nFilesystem\nFilesystem\nFilesystem\nPostgreSQL\nFilesystem\nFilesystem\nFilesystem\nFilesystem\nFilesystem\nFilesystem\nFilesystem\nFilesystem\nPostgreSQL\nFilesystem\nFilesystem\nFilesystem\nFilesystem\nFilesystem\nDatasets in Project:  CUSTOMER_CHURN_BROKEN\nUploadedFiles\nFilesystem\nUploadedFiles\nUploadedFiles\nFilesystem\nPostgreSQL\nFilesystem\nFilesystem\nPostgreSQL\nPostgreSQL\nPostgreSQL\nPostgreSQL\nDatasets in Project:  DKU_TSHIRTS\nFilesystem\nUploadedFiles\nUploadedFiles\nFilesystem\nFilesystem\nUploadedFiles\nFilesystem\nUploadedFiles\nFilesystem\nUploadedFiles\nFilesystem\nDatasets in Project:  DKU_TUTORIAL_BASICS_101\nDatasets in Project:  GROUP_A_PROJECT\nUploadedFiles\nPostgreSQL\nDatasets in Project:  GROUP_B_PROJECT\nPostgreSQL\nDatasets in Project:  THEBIGSLEEP\nUploadedFiles\nFilesystem\nFilesystem\nFilesystem\nFilesystem\nFilesystem\nFilesystem\n",
          "name": "stdout"
        }
      ]
    },
    {
      "execution_count": 10,
      "cell_type": "code",
      "metadata": {
        "code_folding": []
      },
      "source": [
        "index \u003d 0\nfor dataset in datasets:\n    #pp.pprint(dataset)\n    print(dataset)\n    if dataset.type \u003d\u003d \u0027Snowflake\u0027:\n        dataset_to_update \u003d prj.get_dataset(dataset.name)\n        # Get dataset settings\n        settings \u003d dataset_to_update.get_settings()\n        # get raw dataset settings, which is editable\n        settings_raw \u003d settings.get_raw()\n        # pp.pprint(settings_raw[\u0027params\u0027])\n        if \u0027schema\u0027 in settings_raw[\u0027params\u0027]:\n            if settings_raw[\u0027params\u0027][\u0027schema\u0027] in [\u0027AWB_CDW\u0027,\u0027AWB_CDL\u0027, \u0027AWB_ADHOC\u0027,\u0027AWB_DATAIKU_CDW\u0027, \u0027AWB_DATAIKU_CDL\u0027,\u0027AWB_DATAIKU_ADHOC\u0027]:\n                new_values \u003d workflow_Alteration_df[workflow_Alteration_df[\u0027Existing_Source\u0027.strip()] \u003d\u003d settings_raw[\u0027params\u0027][\u0027table\u0027]]\n                update_check \u003d new_values.empty\n                if not new_values.empty:\n                    print(\"Inside If\", update_check, new_values,\"*****\", new_values.index[0])\n                    settings_raw[\u0027params\u0027][\u0027catalog\u0027] \u003d new_values[\u0027GB_Database\u0027.strip()][new_values.index[0]]\n                    settings_raw[\u0027params\u0027][\u0027schema\u0027] \u003d new_values[\u0027GB_Schema\u0027.strip()][new_values.index[0]]\n                    settings_raw[\u0027params\u0027][\u0027table\u0027] \u003d new_values[\u0027GB_TBL_Name\u0027.strip()][new_values.index[0]]\n                    settings.save()\n                    settings_raw[\"schema\"] \u003d {\"columns\":[]}\n                    settings.save()\n                    settings \u003d dataset_to_update.autodetect_settings()\n                    settings.save()\n                    new_values \u003d None\n                    index +\u003d 1"
      ],
      "outputs": []
    },
    {
      "execution_count": 0,
      "cell_type": "code",
      "metadata": {},
      "source": [
        ""
      ],
      "outputs": []
    }
  ]
}